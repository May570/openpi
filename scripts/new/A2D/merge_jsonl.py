#!/usr/bin/env python3
"""
åˆå¹¶6Dç‰ˆæœ¬çš„ä¸¤å¥—JSONLæ–‡ä»¶ï¼ˆ320x240å’Œ640x480ï¼‰
å¤„ç†å®Œæˆååˆ é™¤åŸåˆ†ç‰‡æ–‡ä»¶
"""
import os
import glob
import json
from pathlib import Path
from tqdm import tqdm


def merge_jsonl_by_resolution(data_dir, task_name, resolution):
    """
    åˆå¹¶æŒ‡å®šåˆ†è¾¨ç‡çš„æ‰€æœ‰JSONLåˆ†ç‰‡

    Args:
        data_dir: JSONLæ–‡ä»¶æ‰€åœ¨ç›®å½•
        task_name: ä»»åŠ¡åç§°ï¼ˆå€’æ°´/æŠ½å±‰/æ“¦é»‘æ¿ï¼‰
        resolution: åˆ†è¾¨ç‡æ ‡è¯†ï¼Œå¦‚ "320x240" æˆ– "640x480"
    """
    data_dir = Path(data_dir)
    
    # æŸ¥æ‰¾ä»»åŠ¡ç›®å½•ä¸‹çš„åˆ†ç‰‡JSONLæ–‡ä»¶
    task_dir = data_dir / task_name
    pattern = str(task_dir / f"a2d_train_{task_name}_{resolution}_*_*.jsonl")
    jsonl_files = sorted(glob.glob(pattern))

    if not jsonl_files:
        print(f"âŒ æœªæ‰¾åˆ°ä»»ä½• {resolution} çš„JSONLæ–‡ä»¶: {pattern}")
        return False

    print(f"\n{'='*60}")
    print(f"ğŸ“Š å¤„ç† {resolution} ç‰ˆæœ¬")
    print(f"{'='*60}")
    print(f"æ‰¾åˆ° {len(jsonl_files)} ä¸ªåˆ†ç‰‡æ–‡ä»¶")

    # ç»Ÿè®¡åŸå§‹æ–‡ä»¶ä¿¡æ¯
    total_lines = 0
    file_info = []

    for file_path in jsonl_files:
        with open(file_path, "r", encoding="utf-8") as f:
            line_count = sum(1 for _ in f)
            total_lines += line_count
            file_info.append((Path(file_path).name, line_count))

    print(f"\nğŸ“ åŸå§‹æ–‡ä»¶ç»Ÿè®¡:")
    for name, count in file_info[:3]:
        print(f"   {name}: {count} è¡Œ")
    if len(file_info) > 6:
        print(f"   ... (å…± {len(file_info)} ä¸ªæ–‡ä»¶)")
        for name, count in file_info[-3:]:
            print(f"   {name}: {count} è¡Œ")
    else:
        for name, count in file_info[3:]:
            print(f"   {name}: {count} è¡Œ")
    print(f"\nâœ… æ€»è¡Œæ•°: {total_lines}")

    # åˆå¹¶æ–‡ä»¶
    output_filename = f"a2d_train_{task_name}_{resolution}_merged.jsonl"
    output_path = task_dir / output_filename
    temp_output_path = task_dir / f"{output_filename}.tmp"

    print(f"\nğŸ”„ å¼€å§‹åˆå¹¶æ–‡ä»¶...")
    print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")

    merged_count = 0

    try:
        with open(temp_output_path, "w", encoding="utf-8") as out_f:
            for file_path in tqdm(jsonl_files, desc="åˆå¹¶è¿›åº¦"):
                with open(file_path, "r", encoding="utf-8") as in_f:
                    for line in in_f:
                        line = line.strip()
                        if line:
                            try:
                                json.loads(line)
                                out_f.write(line + "\n")
                                merged_count += 1
                            except json.JSONDecodeError as e:
                                print(
                                    f"\nâš ï¸  è·³è¿‡æ— æ•ˆJSONè¡Œ in {Path(file_path).name}: {e}"
                                )

        # é‡å‘½åä¸´æ—¶æ–‡ä»¶ä¸ºæœ€ç»ˆæ–‡ä»¶
        temp_output_path.rename(output_path)

        print(f"\nâœ… åˆå¹¶å®Œæˆ!")
        print(f"   åˆå¹¶è¡Œæ•°: {merged_count}")
        print(f"   é¢„æœŸè¡Œæ•°: {total_lines}")

        if merged_count != total_lines:
            print(f"âš ï¸  è¡Œæ•°ä¸åŒ¹é…ï¼å·®å¼‚: {total_lines - merged_count}")

        # éªŒè¯åˆå¹¶åçš„æ–‡ä»¶
        print(f"\nğŸ” éªŒè¯åˆå¹¶æ–‡ä»¶...")
        with open(output_path, "r", encoding="utf-8") as f:
            verify_count = sum(1 for _ in f)

        if verify_count == merged_count:
            print(f"âœ… éªŒè¯é€šè¿‡: {verify_count} è¡Œ")
        else:
            print(f"âŒ éªŒè¯å¤±è´¥: å†™å…¥{merged_count}è¡Œ, å®é™…{verify_count}è¡Œ")
            return False

        # åˆ é™¤åŸå§‹åˆ†ç‰‡æ–‡ä»¶
        print(f"\nğŸ—‘ï¸  åˆ é™¤åŸå§‹åˆ†ç‰‡æ–‡ä»¶...")
        deleted_count = 0
        for file_path in tqdm(jsonl_files, desc="åˆ é™¤è¿›åº¦"):
            try:
                os.remove(file_path)
                deleted_count += 1
            except Exception as e:
                print(f"\nâš ï¸  åˆ é™¤å¤±è´¥ {Path(file_path).name}: {e}")

        print(f"âœ… å·²åˆ é™¤ {deleted_count}/{len(jsonl_files)} ä¸ªåŸå§‹æ–‡ä»¶")
        print(f"\nğŸ‰ {resolution} ç‰ˆæœ¬å¤„ç†å®Œæˆ!")
        print(f"   æœ€ç»ˆæ–‡ä»¶: {output_path}")
        print(f"   æ€»è¡Œæ•°: {verify_count}")
        print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / (1024**2):.2f} MB")

        return True

    except Exception as e:
        print(f"\nâŒ åˆå¹¶å¤±è´¥: {e}")
        if temp_output_path.exists():
            temp_output_path.unlink()
        return False


def main():
    import argparse

    parser = argparse.ArgumentParser(description="åˆå¹¶A2Dä»»åŠ¡çš„åˆ†ç‰‡JSONLæ–‡ä»¶")
    parser.add_argument(
        "--task_name",
        type=str,
        required=True,
        choices=["pour_coffee_105_", "open_close", "erase", "pnp"],
        help="ä»»åŠ¡ç±»å‹: pour (å€’æ°´), open_close (å¼€å…³æŠ½å±‰), erase (æ“¦é»‘æ¿), pnp(æŠ“å–æ”¾ç½®)",
    )
    parser.add_argument(
        "--data_dir",
        type=str,
        default="/share/project/fengli/data",
        help="JSONLæ–‡ä»¶æ‰€åœ¨ç›®å½•",
    )
    parser.add_argument("--dry-run", action="store_true", help="è¯•è¿è¡Œï¼Œåªç»Ÿè®¡ä¸åˆå¹¶")

    args = parser.parse_args()

    if args.dry_run:
        print(f"ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸ä¼šä¿®æ”¹æ–‡ä»¶ï¼‰")
        print(f"ä»»åŠ¡ç±»å‹: {args.task_name}")
        data_dir = Path(args.data_dir)

        for resolution in ["320x240", "640x480"]:
            pattern = str(
                data_dir / f"a2d_train_{args.task_name}_{resolution}_*_*.jsonl"
            )
            jsonl_files = sorted(glob.glob(pattern))

            print(f"\n{resolution} æ‰¾åˆ° {len(jsonl_files)} ä¸ªæ–‡ä»¶:")
            total = 0
            for f in jsonl_files[:5]:
                with open(f, "r") as file:
                    count = sum(1 for _ in file)
                    total += count
                    print(f"  {Path(f).name}: {count} è¡Œ")
            if len(jsonl_files) > 5:
                print(f"  ... (å…± {len(jsonl_files)} ä¸ªæ–‡ä»¶)")
            print(f"æ€»è®¡: {total} è¡Œ (å·²ç»Ÿè®¡å‰5ä¸ª)")
    else:
        print("=" * 60)
        print(f"ğŸš€ å¼€å§‹åˆå¹¶ã€{args.task_name}ã€‘ä»»åŠ¡çš„JSONLæ–‡ä»¶")
        print("=" * 60)

        # åˆå¹¶320x240ç‰ˆæœ¬
        success_320 = merge_jsonl_by_resolution(
            args.data_dir, args.task_name, "320x240"
        )

        # åˆå¹¶640x480ç‰ˆæœ¬
        success_640 = merge_jsonl_by_resolution(
            args.data_dir, args.task_name, "640x480"
        )

        print(f"\n{'='*60}")
        print("ğŸ“Š æœ€ç»ˆç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"320x240 ç‰ˆæœ¬: {'âœ… æˆåŠŸ' if success_320 else 'âŒ å¤±è´¥'}")
        print(f"640x480 ç‰ˆæœ¬: {'âœ… æˆåŠŸ' if success_640 else 'âŒ å¤±è´¥'}")

        if success_320 and success_640:
            print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
            print(f"\næœ€ç»ˆç”Ÿæˆæ–‡ä»¶:")
            print(
                f"  - {args.data_dir}/a2d_train_{args.task_name}_320x240_merged.jsonl"
            )
            print(
                f"  - {args.data_dir}/a2d_train_{args.task_name}_640x480_merged.jsonl"
            )
        else:
            print(f"\nâš ï¸  éƒ¨åˆ†ä»»åŠ¡å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")


if __name__ == "__main__":
    main()
